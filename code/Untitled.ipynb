{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1713862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -m MODE -s SETTINGS [-n MODEL] [-o OUTPUT]\n",
      "                             [-k SCORE_KEY]\n",
      "ipykernel_launcher.py: error: the following arguments are required: -m/--mode, -s/--settings\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import loguniform, uniform\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from IPython import embed\n",
    "\n",
    "def convert(o):\n",
    "    if isinstance(o, np.int64): return int(o)  \n",
    "    raise TypeError\n",
    "\n",
    "def select_hyperparams(config, output_name, model, is_arc, score_key='f_macro'):\n",
    "    ### make directories\n",
    "    config_path, checkpoint_path, result_path = make_dirs(config)\n",
    "\n",
    "    setup_params = ['tune_params', 'num_search_trials', 'dir_name']\n",
    "    model_params = set()\n",
    "    for p in config:\n",
    "        if p in setup_params or ('range' in p or 'algo' in p or 'type' in p or p.startswith('CON')): continue\n",
    "        model_params.add(p)\n",
    "    print(\"[model params] {}\".format(model_params))\n",
    "\n",
    "    score_lst = []\n",
    "    time_lst = []\n",
    "    best_epoch_lst = []\n",
    "    tn2vals = dict()\n",
    "    for trial_num in range(int(config['num_search_trials'])):\n",
    "        ### sample values\n",
    "        print(\"[trial {}] Starting...\".format(trial_num))\n",
    "        print(\"[trial {}] sampling parameters in {}\".format(trial_num, config['tune_params']))\n",
    "\n",
    "        constraints_OK = False\n",
    "        while not constraints_OK:\n",
    "            p2v = sample_values(trial_num)\n",
    "            constraints_OK = check_constraints(config, p2v)\n",
    "        tn2vals[trial_num] = p2v\n",
    "\n",
    "        ### construct the appropriate config file\n",
    "        config_file_name = config_path + 'config-{}.txt'.format(trial_num)\n",
    "        print(\"[trial {}] writing configuration to {}\".format(trial_num, config_file_name))\n",
    "        print(\"[trial {}] checkpoints to {}\".format(trial_num, checkpoint_path))\n",
    "        print(\"[trial {}] results to {}\".format(trial_num, result_path))\n",
    "        f = open(config_file_name, 'w')\n",
    "        model_name = '{}_t{}'.format(config['name'], trial_num)\n",
    "        f.write('name:{}\\n'.format(model_name)) # include trial number in name\n",
    "        f.write('ckp_path:{}\\n'.format(checkpoint_path)) # checkpoint save location\n",
    "        f.write('res_path:{}\\n'.format(result_path)) # results save location\n",
    "        for p in model_params:\n",
    "            if p == 'name': continue\n",
    "            f.write('{}:{}\\n'.format(p, config[p]))\n",
    "        for p in p2v:\n",
    "            f.write('{}:{}\\n'.format(p, p2v[p]))\n",
    "        f.flush()\n",
    "\n",
    "        ### run the script\n",
    "        print(\"[trial {}] running cross validation\".format(trial_num))\n",
    "        start_time = time.time()\n",
    "        if model == 'adv':\n",
    "            os.system(\"./adv_train.sh 1 {} 0 {} > {}log_t{}.txt\".format(config_file_name, score_key, result_path, trial_num))\n",
    "        elif model == 'bicond':\n",
    "            os.system(\"./bicond.sh {} {} > {}log_t{}.txt\".format(config_file_name, score_key, result_path, trial_num))\n",
    "        else:\n",
    "            print(\"ERROR: model {} is not supported\".format(model))\n",
    "            sys.exit(1)\n",
    "        script_time = (time.time() - start_time) / 60.\n",
    "        print(\"[trial {}] running on ARC took {:.4f} minutes\".format(trial_num, script_time))\n",
    "\n",
    "        ### process the result and update information on best\n",
    "        if model == 'adv':\n",
    "            res_f = open('{}{}_t{}-{}.top5_{}.txt'.format(result_path, config['name'], trial_num, config['enc'], score_key), 'r')\n",
    "        else:\n",
    "            res_f = open('{}{}_t{}.top5_{}.txt'.format(result_path, config['name'], trial_num, score_key), 'r')\n",
    "        res_lines = res_f.readlines()\n",
    "        score_lst.append(res_lines[-2].strip().split(':')[1])\n",
    "        time_lst.append(script_time)\n",
    "        best_epoch_lst.append(res_lines[-3].strip().split(':')[1])\n",
    "\n",
    "        print(\"[trial {}] Done.\".format(trial_num))\n",
    "        print()\n",
    "\n",
    "    ### save the resulting scores and times, for calculating the expected validation f1\n",
    "    data = []\n",
    "    for ti in tn2vals:\n",
    "        data.append([ti, score_lst[ti], time_lst[ti], best_epoch_lst[ti], json.dumps(tn2vals[ti], default=convert)])\n",
    "    df = pd.DataFrame(data, columns=['trial_num', 'avg_score', 'time', 'best_epoch', 'param_vals'])\n",
    "    df.to_csv('data/model_results/{}-{}trials/{}'.format(config['dir_name'], config['num_search_trials'],\n",
    "                                                      output_name), index=False)\n",
    "    print(\"results to {}\".format(output_name))\n",
    "\n",
    "\n",
    "def parse_config(fname):\n",
    "    f = open(fname, 'r')\n",
    "    lines = f.readlines()\n",
    "    n2info = dict()\n",
    "    for l in lines:\n",
    "        n, info = l.strip().split(':')\n",
    "        n2info[n] = info\n",
    "\n",
    "    n2info['tune_params'] = n2info['tune_params'].split(',')\n",
    "    for p in n2info['tune_params']:\n",
    "        t = n2info['{}_type'.format(p)]\n",
    "        n2info['{}_range'.format(p)] = list(map(lambda x: int(x) if t == 'int' else\n",
    "                                                    float(x) if t == 'float' else x,\n",
    "                                                    n2info['{}_range'.format(p)].split('-')))\n",
    "    return n2info\n",
    "\n",
    "\n",
    "def sample_values(trial_num):\n",
    "    p2v = dict()\n",
    "    for p in config['tune_params']:\n",
    "        a = config['{}_algo'.format(p)]\n",
    "        if a == 'selection':        #To select in order from a list of hyperparam values\n",
    "            p2v[p] = config['{}_range'.format(p)][trial_num]\n",
    "        elif a == 'choice':         #To randomly select any value from a list of hyperparam values\n",
    "            p2v[p] = np.random.choice(config['{}_range'.format(p)])\n",
    "        else:                       #To randomly select a value from a given range\n",
    "            min_v, max_v = config['{}_range'.format(p)]\n",
    "            if a == 'loguniform':\n",
    "                p2v[p] = loguniform.rvs(min_v, max_v)\n",
    "            elif a == 'uniform-integer':\n",
    "                p2v[p] = np.random.randint(min_v, max_v + 1)\n",
    "            elif a == 'uniform-float':\n",
    "                p2v[p] = uniform.rvs(min_v, max_v)\n",
    "            else:\n",
    "                print(\"ERROR: sampling method specified as {}\".format(a))\n",
    "\n",
    "    return p2v\n",
    "\n",
    "\n",
    "def check_constraints(n2info, p2v):\n",
    "    constraints_OK = True\n",
    "    for n in n2info:\n",
    "        if not n.startswith('CON'): continue\n",
    "        eq = n2info[n].split('#') # equations should be in format param1#symbol#param2\n",
    "        if len(eq) == 3:\n",
    "            con_res = parse_equation(p2v[eq[0]], eq[1], p2v[eq[2]])\n",
    "        elif len(eq) == 4:\n",
    "            if eq[0] in p2v:\n",
    "                v1 = p2v[eq[0]]\n",
    "                s = eq[1]\n",
    "                v2 = float(eq[2]) * p2v[eq[3]]\n",
    "            else:\n",
    "                v1 = float(eq[0]) * p2v[eq[1]]\n",
    "                s = eq[2]\n",
    "                v2 = p2v[eq[3]]\n",
    "            con_res = parse_equation(v1, s, v2)\n",
    "        else:\n",
    "            print(\"ERROR: equation not parsable {}\".format(eq))\n",
    "            sys.exit(1)\n",
    "        constraints_OK = con_res and constraints_OK\n",
    "    return constraints_OK\n",
    "\n",
    "\n",
    "def parse_equation(v1, s, v2):\n",
    "    if s == '<': return v1 < v2\n",
    "    elif s == '<=': return v1 <= v2\n",
    "    elif s == '=': return v1 == v2\n",
    "    elif s == '!=': return v1 != v2\n",
    "    elif s == '>': return v1 > v2\n",
    "    elif s == '>=': return v1 >= v2\n",
    "    else:\n",
    "        print(\"ERROR: symbol {} not recognized\".format(s))\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "def make_dirs(config):\n",
    "    config_path = 'data/config/{}-{}trials/'.format(config['dir_name'],\n",
    "                                                    config['num_search_trials'])\n",
    "    checkpoint_path = 'data/checkpoints/{}-{}trials/'.format(config['dir_name'],\n",
    "                                                             config['num_search_trials'])\n",
    "    result_path = 'data/model_results/{}-{}trials/'.format(config['dir_name'],\n",
    "                                             config['num_search_trials'])\n",
    "    for p_name, p_path in [('config_path', config_path), ('ckp_path', checkpoint_path),\n",
    "                           ('result_path', result_path)]:\n",
    "        if not os.path.exists(p_path):\n",
    "            os.makedirs(p_path)\n",
    "        else:\n",
    "            print(\"[{}] Directory {} already exists!\".format(p_name, p_path))\n",
    "            sys.exit(1)\n",
    "    return config_path, checkpoint_path, result_path\n",
    "\n",
    "\n",
    "def remove_dirs(config):\n",
    "    config_path = 'data/config/{}-{}trials/'.format(config['dir_name'],\n",
    "                                                    config['num_search_trials'])\n",
    "    checkpoint_path = 'data/checkpoints/{}-{}trials/'.format(config['dir_name'],\n",
    "                                                             config['num_search_trials'])\n",
    "    result_path = 'data/model_results/{}-{}trials/'.format(config['dir_name'],\n",
    "                                             config['num_search_trials'])\n",
    "    for p_name, p_path in [('config_path', config_path), ('ckp_path', checkpoint_path),\n",
    "                           ('result_path', result_path)]:\n",
    "        if not os.path.exists(p_path):\n",
    "            print(\"[{}] directory {} doesn't exist\".format(p_name, p_path))\n",
    "            continue\n",
    "        else:\n",
    "            print(\"[{}] removing all files from {}\".format(p_name, p_path))\n",
    "            for fname in os.listdir(p_path):\n",
    "                os.remove(os.path.join(p_path, fname))\n",
    "            print(\"[{}] removing empty directory\".format(p_name))\n",
    "            os.rmdir(p_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-m', '--mode', help='What to do', required=True)\n",
    "    parser.add_argument('-s', '--settings', help='Name of the file containing hyperparam info', required=True)\n",
    "    # model_name should be bert-text-level or adv or bicond currently and is to be specified when is_arc is True.\n",
    "    parser.add_argument('-n', '--model', help='Name of the model to run', required=False, default='adv')\n",
    "    parser.add_argument('-o', '--output', help='Name of the output file (full path)', required=False,\n",
    "                        default='trial_results.csv')\n",
    "    parser.add_argument('-k', '--score_key', help='Score key for optimization', required=False, default='f_macro')\n",
    "    args = vars(parser.parse_args())\n",
    "\n",
    "    config = parse_config(args['settings'])\n",
    "\n",
    "    if args['mode'] == '1':\n",
    "        ## run hyperparam search\n",
    "        remove_dirs(config)\n",
    "        select_hyperparams(config, args['output'], args['model'], is_arc=('arc' in args['settings'] or 'twitter' in args['settings']), score_key=args['score_key'])\n",
    "    elif args['mode'] == '2':\n",
    "        ## remove directories\n",
    "        remove_dirs(config)\n",
    "    else:\n",
    "        print(\"ERROR. exiting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a64d0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "python train_and_eval_model.py [-h] -m \"train\" -s SETTINGS [-n MODEL] [-o OUTPUT]\n",
    "                             [-k SCORE_KEY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0444d5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (289735962.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [26]\u001b[1;36m\u001b[0m\n\u001b[1;33m    python train_and_eval_model.py --mode \"train\" --config_file config_example_toad.txt --trn_data data/twitter_data_naacl/twitter_testA_seenval/train.csv --dev_data data/twitter_data_naacl/twitter_testA_seenval/validation.csv --score_key f_macro --topics_vocab data/resources/twitter-topic-TRN-semi-sup.vocab.pkl --mode train\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python train_and_eval_model.py --mode \"train\" --config_file config_example_toad.txt --trn_data data/twitter_data_naacl/twitter_testA_seenval/train.csv --dev_data data/twitter_data_naacl/twitter_testA_seenval/validation.csv --score_key f_macro --topics_vocab data/resources/twitter-topic-TRN-semi-sup.vocab.pkl --mode train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28bf4fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pickle, time, json, copy\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "class TorchModelHandler:\n",
    "    '''\n",
    "    Class that holds a model and provides the functionality to train it,\n",
    "    save it, load it, and evaluate it. The model used here is assumed to be\n",
    "    written in pytorch.\n",
    "    '''\n",
    "    # def __init__(self, model, loss_function, dataloader, optimizer, name, num_ckps=10,\n",
    "    #              use_score='f_macro', device='cpu', use_last_batch=True):\n",
    "    def __init__(self, num_ckps=10, use_score='f_macro', use_cuda=False,\n",
    "                 checkpoint_path='data/checkpoints/',\n",
    "                 result_path='data/', **params):\n",
    "        super(TorchModelHandler, self).__init__()\n",
    "        # data fields\n",
    "        self.model = params['model']\n",
    "        self.embed_model = params['embed_model']\n",
    "        self.dataloader = params['dataloader']\n",
    "        self.batching_fn = params['batching_fn']\n",
    "        self.batching_kwargs = params['batching_kwargs']\n",
    "        self.setup_fn = params['setup_fn']\n",
    "\n",
    "        self.num_labels = self.model.num_labels\n",
    "        self.name = params['name']\n",
    "\n",
    "        # optimization fields\n",
    "        self.loss_function = params['loss_function']\n",
    "        self.optimizer = params['optimizer']\n",
    "        self.fine_tune = params.get('fine_tune', False)\n",
    "\n",
    "        # stats fields\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.checkpoint_num = 0\n",
    "        self.num_ckps = num_ckps\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.result_path = result_path\n",
    "\n",
    "        # evaluation fields\n",
    "        self.score_dict = dict()\n",
    "        self.max_score = 0.\n",
    "        self.max_lst = []  # to keep top 5 scores\n",
    "        self.score_key = use_score\n",
    "        self.blackout_start = params['blackout_start']\n",
    "        self.blackout_stop = params['blackout_stop']\n",
    "\n",
    "        # GPU support\n",
    "        self.use_cuda = use_cuda\n",
    "        if self.use_cuda:\n",
    "            # move model and loss function to GPU, NOT the embedder\n",
    "            self.model = self.model.to('cuda')\n",
    "            self.loss_function = self.loss_function.to('cuda')\n",
    "\n",
    "    def save_best(self, data=None, scores=None, data_name=None, class_wise=False):\n",
    "        '''\n",
    "        Evaluates the model on data and then updates the best scores and saves the best model.\n",
    "        :param data: data to evaluate and update based on. Default (None) will evaluate on the internally\n",
    "                        saved data. Otherwise, should be a DataSampler. Only used if scores is not None.\n",
    "        :param scores: a dictionary of precomputed scores. Default (None) will compute a list of scores\n",
    "                        using the given data, name and class_wise flag.\n",
    "        :param data_name: the name of the data evaluating and updating on. Only used if scores is not None.\n",
    "        :param class_wise: lag to determine whether to compute class-wise scores in\n",
    "                            addition to macro-averaged scores. Only used if scores is not None.\n",
    "        '''\n",
    "        if scores is None:\n",
    "            # evaluate and print\n",
    "            scores = self.eval_and_print(data=data, data_name=data_name,\n",
    "                                         class_wise=class_wise)\n",
    "        scores = copy.deepcopy(scores)  # copy the scores, otherwise storing a pointer which won't track properly\n",
    "\n",
    "        if self.epoch in range(self.blackout_start, self.blackout_stop):\n",
    "            return\n",
    "            # update list of top scores\n",
    "        curr_score = scores[self.score_key]\n",
    "        score_updated = False\n",
    "        if len(self.max_lst) < 5:\n",
    "            score_updated = True\n",
    "            if len(self.max_lst) > 0:\n",
    "                prev_max = self.max_lst[-1][0][self.score_key] # last thing in the list\n",
    "            else:\n",
    "                prev_max = curr_score\n",
    "            self.max_lst.append((scores, self.epoch - 1))\n",
    "        elif curr_score > self.max_lst[0][0][self.score_key]: # if bigger than the smallest score\n",
    "            score_updated = True\n",
    "            prev_max = self.max_lst[-1][0][self.score_key] # last thing in the list\n",
    "            self.max_lst[0] = (scores, self.epoch - 1) #  replace smallest score\n",
    "\n",
    "        # update best saved model and file with top scores\n",
    "        if score_updated:\n",
    "            # prev_max = self.max_lst[-1][0][self.score_key]\n",
    "            # sort the scores\n",
    "            self.max_lst = sorted(self.max_lst, key=lambda p: p[0][self.score_key])  # lowest first\n",
    "            # write top 5 scores\n",
    "            f = open('{}{}.top5_{}.txt'.format(self.result_path, self.name, self.score_key), 'w')  # overrides\n",
    "            for p in self.max_lst:\n",
    "                f.write('Epoch: {}\\nScore: {}\\nAll Scores: {}\\n'.format(p[1], p[0][self.score_key],\n",
    "                                                                            json.dumps(p[0])))\n",
    "            # save best model step, if its this one\n",
    "            print(curr_score, prev_max)\n",
    "            if curr_score > prev_max or self.epoch == 1:\n",
    "                self.save(num='BEST')\n",
    "\n",
    "    def save(self, num=None):\n",
    "        '''\n",
    "        Saves the pytorch model in a checkpoint file.\n",
    "        :param num: The number to associate with the checkpoint. By default uses\n",
    "                    the internally tracked checkpoint number but this can be changed.\n",
    "        '''\n",
    "        if num is None:\n",
    "            check_num = self.checkpoint_num\n",
    "        else: check_num = num\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': self.epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'loss': self.loss\n",
    "        }, '{}ckp-{}-{}.tar'.format(self.checkpoint_path, self.name, check_num))\n",
    "\n",
    "        if num is None:\n",
    "            self.checkpoint_num = (self.checkpoint_num + 1) % self.num_ckps\n",
    "\n",
    "    def load(self, filename='data/checkpoints/ckp-[NAME]-FINAL.tar', use_cpu=False):\n",
    "        '''\n",
    "        Loads a saved pytorch model from a checkpoint file.\n",
    "        :param filename: the name of the file to load from. By default uses\n",
    "                        the final checkpoint for the model of this' name.\n",
    "        '''\n",
    "        filename = filename.replace('[NAME]', self.name)\n",
    "        checkpoint = torch.load(filename)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    def train_step(self):\n",
    "        '''\n",
    "        Runs one epoch of training on this model.\n",
    "        '''\n",
    "        print(\"[{}] epoch {}\".format(self.name, self.epoch))\n",
    "        self.model.train()\n",
    "        self.loss = 0.  # clear the loss\n",
    "        start_time = time.time()\n",
    "        for i_batch, sample_batched in enumerate(self.dataloader):\n",
    "\n",
    "            # zero gradients before EVERY optimizer step\n",
    "            self.model.zero_grad()\n",
    "            if self.tune_embeds:\n",
    "                self.embed_model.zero_grad()\n",
    "\n",
    "            y_pred, labels = self.get_pred_with_grad(sample_batched)\n",
    "\n",
    "            label_tensor = torch.tensor(labels)\n",
    "            if self.use_cuda:\n",
    "                # move labels to cuda if necessary\n",
    "                label_tensor = label_tensor.to('cuda')\n",
    "\n",
    "            if self.dataloader.weighting:\n",
    "                batch_loss = self.loss_function(y_pred, label_tensor)\n",
    "                weight_lst = torch.tensor([self.dataloader.topic2c2w[b['ori_topic']][b['label']]\n",
    "                                           for b in sample_batched])\n",
    "                if self.use_cuda:\n",
    "                    weight_lst = weight_lst.to('cuda')\n",
    "                graph_loss = torch.mean(batch_loss * weight_lst)\n",
    "            else:\n",
    "                graph_loss = self.loss_function(y_pred, label_tensor)\n",
    "\n",
    "            # self.loss = graph_loss.item()\n",
    "            self.loss += graph_loss.item()  # update loss\n",
    "\n",
    "            graph_loss.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "        end_time = time.time()\n",
    "        # self.dataloader.reset()\n",
    "        print(\"   took: {:.1f} min\".format((end_time - start_time)/60.))\n",
    "        self.epoch += 1\n",
    "\n",
    "    def compute_scores(self, score_fn, true_labels, pred_labels, class_wise, name):\n",
    "        '''\n",
    "        Computes scores using the given scoring function of the given name. The scores\n",
    "        are stored in the internal score dictionary.\n",
    "        :param score_fn: the scoring function to use.\n",
    "        :param true_labels: the true labels.\n",
    "        :param pred_labels: the predicted labels.\n",
    "        :param class_wise: flag to determine whether to compute class-wise scores in\n",
    "                            addition to macro-averaged scores.\n",
    "        :param name: the name of this score function, to be used in storing the scores.\n",
    "        '''\n",
    "        labels = [i for i in range(2)]\n",
    "        n = float(len(labels))\n",
    "\n",
    "        vals = score_fn(true_labels, pred_labels, labels=labels, average=None)\n",
    "        self.score_dict['{}_macro'.format(name)] = sum(vals) / n\n",
    "\n",
    "        if class_wise:\n",
    "            self.score_dict['{}_anti'.format(name)] = vals[0]\n",
    "            self.score_dict['{}_pro'.format(name)] = vals[1]\n",
    "            if n > 2:\n",
    "                self.score_dict['{}_none'.format(name)] = vals[2]\n",
    "\n",
    "    def eval_model(self, data=None, class_wise=False, data_name=None):\n",
    "        '''\n",
    "        Evaluates this model on the given data. Stores computed\n",
    "        scores in the field \"score_dict\". Currently computes macro-averaged\n",
    "        F1 scores, precision and recall. Can also compute scores on a class-wise basis.\n",
    "        :param data: the data to use for evaluation. By default uses the internally stored data\n",
    "                    (should be a DataSampler if passed as a parameter).\n",
    "        :param class_wise: flag to determine whether to compute class-wise scores in\n",
    "                            addition to macro-averaged scores.\n",
    "        :return: a map from score names to values\n",
    "        '''\n",
    "        pred_labels, true_labels, t2pred, marks = self.predict(data)\n",
    "        self.score(pred_labels, true_labels, class_wise, t2pred, marks)\n",
    "\n",
    "        return self.score_dict\n",
    "\n",
    "    def predict(self, data=None):\n",
    "        all_y_pred = None\n",
    "        all_labels = None\n",
    "        all_marks = None\n",
    "        all_tar_in_twe = None\n",
    "\n",
    "        self.model.eval()\n",
    "        self.loss = 0.\n",
    "\n",
    "        if data is None:\n",
    "            data = self.dataloader\n",
    "\n",
    "        t2pred = dict()\n",
    "        for sample_batched in data:\n",
    "            with torch.no_grad():\n",
    "                # print(sample_batched)\n",
    "                y_pred, labels = self.get_pred_noupdate(sample_batched)\n",
    "\n",
    "                label_tensor = torch.tensor(labels)\n",
    "                if self.use_cuda:\n",
    "                    # move labels to cuda if necessary\n",
    "                    label_tensor = label_tensor.to('cuda')  # .cuda()\n",
    "                self.loss += self.loss_function(y_pred, label_tensor).item()\n",
    "\n",
    "                y_pred_arr = y_pred.detach().cpu().numpy()\n",
    "                ls = np.array(labels)\n",
    "\n",
    "                m = [b['seen'] for b in sample_batched]\n",
    "                tar_in_twe = [b['target_in_tweet'] for b in sample_batched]\n",
    "\n",
    "                for bi, b in enumerate(sample_batched):\n",
    "                    t = b['ori_topic']\n",
    "                    t2pred[t] = t2pred.get(t, ([], []))\n",
    "                    t2pred[t][0].append(y_pred_arr[bi, :])\n",
    "                    t2pred[t][1].append(ls[bi])\n",
    "\n",
    "                if all_y_pred is None:\n",
    "                    all_y_pred = y_pred_arr\n",
    "                    all_labels = ls\n",
    "                    all_marks = m\n",
    "                    all_tar_in_twe = tar_in_twe\n",
    "                else:\n",
    "                    all_y_pred = np.concatenate((all_y_pred, y_pred_arr), 0)\n",
    "                    all_labels = np.concatenate((all_labels, ls), 0)\n",
    "                    all_marks = np.concatenate((all_marks, m), 0)\n",
    "                    all_tar_in_twe = np.concatenate((all_tar_in_twe, tar_in_twe), 0)\n",
    "\n",
    "        for t in t2pred:\n",
    "            t2pred[t] = (np.argmax(t2pred[t][0], axis=1), t2pred[t][1])\n",
    "\n",
    "        if None not in all_tar_in_twe:\n",
    "            all_tar_in_twe = np.array(all_tar_in_twe)\n",
    "            tar_in_twe_mask = np.column_stack((np.zeros(len(all_tar_in_twe)), np.zeros(len(all_tar_in_twe)), all_tar_in_twe))\n",
    "            all_y_pred = np.where(tar_in_twe_mask == 1, -np.inf, all_y_pred)\n",
    "        pred_labels = all_y_pred.argmax(axis=1)\n",
    "        true_labels = all_labels\n",
    "        return pred_labels, true_labels, t2pred, all_marks\n",
    "\n",
    "    def eval_and_print(self, data=None, data_name=None, class_wise=False):\n",
    "        '''\n",
    "        Evaluates this model on the given data. Stores computed\n",
    "        scores in the field \"score_dict\". Currently computes macro-averaged.\n",
    "        Prints the results to the console.\n",
    "        F1 scores, precision and recall. Can also compute scores on a class-wise basis.\n",
    "        :param data: the data to use for evaluation. By default uses the internally stored data\n",
    "                    (should be a DataSampler if passed as a parameter).\n",
    "        :param data_name: the name of the data evaluating.\n",
    "        :param class_wise: flag to determine whether to compute class-wise scores in\n",
    "                            addition to macro-averaged scores.\n",
    "        :return: a map from score names to values\n",
    "        '''\n",
    "        # Passing data_name to eval_model as evaluation of adv model on train and dev are different\n",
    "        scores = self.eval_model(data=data, class_wise=class_wise, data_name=data_name)\n",
    "        print(\"Evaling on \\\"{}\\\" data\".format(data_name))\n",
    "        for s_name, s_val in scores.items():\n",
    "            print(\"{}: {}\".format(s_name, s_val))\n",
    "        return scores\n",
    "\n",
    "    def score(self, pred_labels, true_labels, class_wise, t2pred, marks, topic_wise=False):\n",
    "        '''\n",
    "        Helper Function to compute scores. Stores updated scores in\n",
    "        the field \"score_dict\".\n",
    "        :param pred_labels: the predicted labels\n",
    "        :param true_labels: the correct labels\n",
    "        :param class_wise: flag to determine whether to compute class-wise scores in\n",
    "                            addition to macro-averaged scores.\n",
    "        '''\n",
    "        # calculate class-wise and macro-averaged F1\n",
    "        self.compute_scores(f1_score, true_labels, pred_labels, class_wise, 'f')\n",
    "        # calculate class-wise and macro-average precision\n",
    "        self.compute_scores(precision_score, true_labels, pred_labels, class_wise, 'p')\n",
    "        # calculate class-wise and macro-average recall\n",
    "        self.compute_scores(recall_score, true_labels, pred_labels, class_wise, 'r')\n",
    "\n",
    "        for v in [1, 0]:\n",
    "            tl_lst = []\n",
    "            pl_lst = []\n",
    "            for m, tl, pl in zip(marks, true_labels, pred_labels):\n",
    "                if m != v: continue\n",
    "                tl_lst.append(tl)\n",
    "                pl_lst.append(pl)\n",
    "            self.compute_scores(f1_score, tl_lst, pl_lst, class_wise, 'f-{}'.format(v))\n",
    "            self.compute_scores(precision_score, tl_lst, pl_lst, class_wise, 'p-{}'.format(v))\n",
    "            self.compute_scores(recall_score, tl_lst, pl_lst, class_wise, 'r-{}'.format(v))\n",
    "\n",
    "        if topic_wise:\n",
    "            for t in t2pred:\n",
    "                self.compute_scores(f1_score, t2pred[t][1], t2pred[t][0], class_wise,\n",
    "                                    '{}-f'.format(t))\n",
    "\n",
    "    def get_pred_with_grad(self, sample_batched):\n",
    "        '''\n",
    "        Helper function for getting predictions while tracking gradients.\n",
    "        Used for training the model.\n",
    "        OVERRIDES: super method.\n",
    "        :param sample_batched: the batch of data samples\n",
    "        :return: the predictions for the batch (as a tensor) and the true\n",
    "                    labels for the batch (as a numpy array)\n",
    "        '''\n",
    "        args = self.batching_fn(sample_batched, **self.batching_kwargs)\n",
    "\n",
    "        if not self.fine_tune:\n",
    "            # EMBEDDING\n",
    "            embed_args = self.embed_model(**args)\n",
    "            args.update(embed_args)\n",
    "\n",
    "            # PREDICTION\n",
    "            y_pred = self.model(*self.setup_fn(args, self.use_cuda))\n",
    "\n",
    "        else:\n",
    "            y_pred = self.model(**args)\n",
    "\n",
    "        labels = args['labels']\n",
    "\n",
    "        return y_pred, labels\n",
    "\n",
    "    def get_pred_noupdate(self, sample_batched):\n",
    "        '''\n",
    "        Helper function for getting predictions without tracking gradients.\n",
    "        Used for evaluating the model or getting predictions for other reasons.\n",
    "        OVERRIDES: super method.\n",
    "        :param sample_batched: the batch of data samples\n",
    "        :return: the predictions for the batch (as a tensor) and the true labels\n",
    "                    for the batch (as a numpy array)\n",
    "        '''\n",
    "        args = self.batching_fn(sample_batched, **self.batching_kwargs)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if not self.fine_tune:\n",
    "                # EMBEDDING\n",
    "                embed_args = self.embed_model(**args)\n",
    "                args.update(embed_args)\n",
    "\n",
    "                # PREDICTION\n",
    "                y_pred = self.model(*self.setup_fn(args, self.use_cuda))\n",
    "            else:\n",
    "                y_pred = self.model(**args)\n",
    "\n",
    "            labels = args['labels']\n",
    "\n",
    "        return y_pred, labels\n",
    "\n",
    "\n",
    "class AdvTorchModelHandler(TorchModelHandler):\n",
    "    def __init__(self, num_ckps=10, use_score='f_macro', use_cuda=False, use_last_batch=True,\n",
    "                 num_gpus=None, checkpoint_path='data/checkpoints/',\n",
    "                 result_path='data/', opt_for='score_key', **params):\n",
    "        TorchModelHandler.__init__(self, num_ckps=num_ckps, use_score=use_score, use_cuda=use_cuda,\n",
    "                                   use_last_batch=use_last_batch, num_gpus=num_gpus,\n",
    "                                   checkpoint_path=checkpoint_path, result_path=result_path,\n",
    "                                   opt_for=opt_for,\n",
    "                                   **params)\n",
    "        self.adv_optimizer = params['adv_optimizer']\n",
    "        self.tot_epochs = params['tot_epochs']\n",
    "        self.initial_lr = params['initial_lr']\n",
    "        self.alpha = params['alpha']\n",
    "        self.beta = params['beta']\n",
    "        self.num_constant_lr = params['num_constant_lr']\n",
    "        self.batch_size = params['batch_size']\n",
    "\n",
    "    def adjust_learning_rate(self, epoch):\n",
    "        if epoch >= self.num_constant_lr:\n",
    "            tot_epochs_for_calc = self.tot_epochs - self.num_constant_lr\n",
    "            epoch_for_calc = epoch - self.num_constant_lr\n",
    "            p = epoch_for_calc / tot_epochs_for_calc\n",
    "            new_lr = self.initial_lr / ((1 + self.alpha * p) ** self.beta)\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr'] = new_lr\n",
    "            for param_group in self.adv_optimizer.param_groups:\n",
    "                param_group['lr'] = new_lr\n",
    "\n",
    "    def get_learning_rate(self):\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            lr = param_group['lr']\n",
    "            break\n",
    "        return lr\n",
    "\n",
    "    def train_step(self):\n",
    "        '''\n",
    "        Runs one epoch of training on this model.\n",
    "        '''\n",
    "        if self.epoch > 0:  # self.loss_function.use_adv:\n",
    "            self.loss_function.update_param_using_p(self.epoch)  # update the adversarial parameter\n",
    "        print(\"[{}] epoch {}\".format(self.name, self.epoch))\n",
    "        print(\"Adversarial parameter rho - {}\".format(self.loss_function.adv_param))\n",
    "        print(\"Learning rate - {}\".format(self.get_learning_rate()))\n",
    "        self.model.train()\n",
    "        # clear the loss\n",
    "        self.loss = 0.\n",
    "        self.adv_loss = 0\n",
    "        # TRAIN\n",
    "        start_time = time.time()\n",
    "        print(len(self.dataloader))\n",
    "        for i_batch, sample_batched in enumerate(self.dataloader):\n",
    "            print(\"Batch {} in epoch {} -\".format(i_batch, self.epoch))\n",
    "            # zero gradients before EVERY optimizer step\n",
    "            self.model.zero_grad()\n",
    "\n",
    "            pred_info, labels = self.get_pred_with_grad(sample_batched)\n",
    "\n",
    "            label_tensor = torch.tensor(labels, device=('cuda' if self.use_cuda else 'cpu'))    #Getting stance labels\n",
    "            topic_tensor = torch.tensor([b['topic_i'] for b in sample_batched],                 #Getting topic indices for train topics\n",
    "                                        device=('cuda' if self.use_cuda else 'cpu'))\n",
    "            pred_info['W'] = self.model.trans_layer.W\n",
    "            pred_info['topic_i'] = topic_tensor         #Assigning topic indices to this dictionary element which is then used to calc adversarial loss on predicting train data topics\n",
    "\n",
    "            # While training we want to compute adversarial loss.\n",
    "            graph_loss_all, graph_loss_adv = self.loss_function(pred_info, label_tensor, compute_adv_loss=True)\n",
    "            self.loss += graph_loss_all.item()\n",
    "            self.adv_loss += graph_loss_adv.item()\n",
    "            graph_loss_all.backward(retain_graph=True)  # NOT on adv. params\n",
    "            # graph_loss_all.backward(retain_graph=self.loss_function.use_adv) # NOT on adv. params\n",
    "            self.optimizer.step()\n",
    "\n",
    "            print(\"Main loss\", graph_loss_all.item())\n",
    "\n",
    "            self.model.zero_grad()\n",
    "            # if self.loss_function.use_adv:\n",
    "            if True:  # self.loss_function.use_adv: - always do this, train adversary a bit first on it's own\n",
    "                print(\"Adv loss\", graph_loss_adv.item())\n",
    "                graph_loss_adv.backward()\n",
    "                self.adv_optimizer.step()\n",
    "                # only on adv params\n",
    "\n",
    "        end_time = time.time()\n",
    "        # self.dataloader.reset()\n",
    "        print(\"   took: {:.1f} min\".format((end_time - start_time) / 60.))\n",
    "        self.epoch += 1\n",
    "        self.adjust_learning_rate(self.epoch)                # Adjusts the main and adversary optimizer learning rates using logic in base paper.\n",
    "\n",
    "    def predict(self, data=None, data_name='DEV'):\n",
    "        all_y_pred = None\n",
    "        true_labels = None\n",
    "        all_top_pred = None\n",
    "        true_topics = None\n",
    "        all_marks = None\n",
    "        all_tar_in_twe = None\n",
    "\n",
    "        self.model.eval()\n",
    "        self.loss = 0.\n",
    "        self.adv_loss = 0.\n",
    "\n",
    "        if data is None:\n",
    "            data = self.dataloader\n",
    "\n",
    "        t2pred = dict()\n",
    "        for sample_batched in data:\n",
    "            with torch.no_grad():\n",
    "                pred_info, labels = self.get_pred_noupdate(sample_batched)\n",
    "\n",
    "                label_tensor = torch.tensor(labels, device=('cuda' if self.use_cuda else 'cpu'))\n",
    "                pred_info['W'] = self.model.trans_layer.W\n",
    "\n",
    "                if data_name == 'TRAIN':        #Predicting on train data the adversarial loss - irrespective of whether adv is included in main model or not\n",
    "                    topics = [b['topic_i'] for b in sample_batched]\n",
    "                    topic_tensor = torch.tensor(topics, device=('cuda' if self.use_cuda else 'cpu'))\n",
    "                    pred_info['topic_i'] = topic_tensor\n",
    "                    graph_loss_all, graph_loss_adv = self.loss_function(pred_info, label_tensor, compute_adv_loss=True)\n",
    "                else:\n",
    "                    # graph_loss_adv will be 0 - not calculated. graph_loss_all won't include adv loss.\n",
    "                    graph_loss_all, graph_loss_adv = self.loss_function(pred_info, label_tensor, compute_adv_loss=False)\n",
    "\n",
    "                self.loss += graph_loss_all.item()\n",
    "                self.adv_loss += graph_loss_adv.item()\n",
    "\n",
    "                y_pred_arr = pred_info['stance_pred'].detach().cpu().numpy()\n",
    "                ls = np.array(labels)\n",
    "\n",
    "                m = [b['seen'] for b in sample_batched]\n",
    "                tar_in_twe = [b['target_in_tweet'] for b in sample_batched]\n",
    "\n",
    "                if data_name == 'TRAIN':\n",
    "                    top_pred_arr = pred_info['adv_pred'].detach().cpu().numpy()\n",
    "                    tops = np.array(topics)\n",
    "\n",
    "                for bi, b in enumerate(sample_batched):\n",
    "                    t = b['ori_topic']\n",
    "                    t2pred[t] = t2pred.get(t, ([], []))\n",
    "                    t2pred[t][0].append(y_pred_arr[bi, :])\n",
    "                    t2pred[t][1].append(ls[bi])\n",
    "\n",
    "                if all_y_pred is None:\n",
    "                    all_y_pred = y_pred_arr\n",
    "                    true_labels = ls\n",
    "                    all_marks = m\n",
    "                    all_tar_in_twe = tar_in_twe\n",
    "                    if data_name == 'TRAIN':\n",
    "                        all_top_pred = top_pred_arr\n",
    "                        true_topics = tops\n",
    "                else:\n",
    "                    all_y_pred = np.concatenate((all_y_pred, y_pred_arr), 0)\n",
    "                    true_labels = np.concatenate((true_labels, ls), 0)\n",
    "                    all_marks = np.concatenate((all_marks, m), 0)\n",
    "                    all_tar_in_twe = np.concatenate((all_tar_in_twe, tar_in_twe), 0)\n",
    "                    if data_name == 'TRAIN':\n",
    "                        all_top_pred = np.concatenate((all_top_pred, top_pred_arr), 0)\n",
    "                        true_topics = np.concatenate((true_topics, tops), 0)\n",
    "\n",
    "        for t in t2pred:\n",
    "            t2pred[t] = (np.argmax(t2pred[t][0], axis=1), t2pred[t][1])\n",
    "\n",
    "        if None not in all_tar_in_twe:\n",
    "            all_tar_in_twe = np.array(all_tar_in_twe)\n",
    "            tar_in_twe_mask = np.column_stack((np.zeros(len(all_tar_in_twe)), np.zeros(len(all_tar_in_twe)), all_tar_in_twe))\n",
    "            all_y_pred = np.where(tar_in_twe_mask == 1, -np.inf, all_y_pred)\n",
    "\n",
    "        pred_labels = all_y_pred.argmax(axis=1)\n",
    "        if data_name == 'TRAIN':\n",
    "            pred_topics = all_top_pred.argmax(axis=1)\n",
    "        else:\n",
    "            pred_topics = None\n",
    "\n",
    "        return pred_labels, true_labels, t2pred, pred_topics, true_topics, all_marks\n",
    "\n",
    "    def eval_model(self, data=None, class_wise=False, data_name='DEV'):\n",
    "        # pred_topics and true_topics will be none while evaluating on dev set\n",
    "        pred_labels, true_labels, t2pred, pred_topics, true_topics, marks = self.predict(data, data_name)\n",
    "        self.score(pred_labels, true_labels, class_wise, t2pred, marks)\n",
    "\n",
    "        # compute score on topic prediction task - used to evaluate adversary performance on train dataset during training\n",
    "        if data_name == 'TRAIN':\n",
    "            self.compute_scores(f1_score, true_topics, pred_topics, class_wise, 'topic-f')\n",
    "\n",
    "        return self.score_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeb88db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from IPython import embed\n",
    "\n",
    "class ReconstructionLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReconstructionLoss, self).__init__()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, ori_embeds, model_embeds, embed_l):\n",
    "        # (B, L, E)\n",
    "        temp = torch.norm(model_embeds - self.tanh(ori_embeds), dim=2) ** 2\n",
    "        lrec = temp.sum(1) / embed_l\n",
    "        return lrec.mean() # combine the loss across the batch\n",
    "\n",
    "\n",
    "class TransformationLoss(torch.nn.Module):\n",
    "    def __init__(self, dim, l, use_cuda=False):\n",
    "        super(TransformationLoss, self).__init__()\n",
    "\n",
    "        self.eye = torch.eye(dim, device='cuda' if use_cuda else 'cpu')\n",
    "        self.l = l\n",
    "\n",
    "    def forward(self, W):\n",
    "        temp =  self.l * torch.norm(W - self.eye) ** 2\n",
    "        return temp\n",
    "\n",
    "\n",
    "class AdvBasicLoss(torch.nn.Module):\n",
    "    def __init__(self, trans_dim, trans_param, num_no_adv=None, tot_epochs=20, rho_adv=False, gamma=10,\n",
    "                 rec_weight=1, semi_sup=False, use_cuda=False):\n",
    "        super(AdvBasicLoss, self).__init__()\n",
    "\n",
    "        self.rec_loss = ReconstructionLoss()\n",
    "        self.trans_loss = TransformationLoss(dim=trans_dim, l=trans_param, use_cuda=use_cuda)\n",
    "\n",
    "        self.adv_param = 0. # start with the adversary weight set to 0\n",
    "\n",
    "\n",
    "        self.semi_sup = semi_sup\n",
    "        if self.semi_sup:\n",
    "            self.stance_loss = nn.CrossEntropyLoss(ignore_index=3)\n",
    "        else:\n",
    "            self.stance_loss = nn.CrossEntropyLoss()\n",
    "        self.topic_loss = nn.CrossEntropyLoss()\n",
    "        #Adversary is not used for num_no_adv initial epochs\n",
    "        self.use_adv = num_no_adv == 0\n",
    "        self.num_no_adv = num_no_adv\n",
    "        self.tot_epochs = tot_epochs\n",
    "        self.rec_weight = rec_weight\n",
    "        self.i = 0\n",
    "        self.rho_adv = rho_adv\n",
    "        self.gamma = gamma\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "    def update_param_using_p(self, epoch):\n",
    "        if epoch >= self.num_no_adv:\n",
    "            self.use_adv = True\n",
    "            tot_epochs_for_calc = self.tot_epochs - self.num_no_adv\n",
    "            epoch_for_calc = epoch - self.num_no_adv\n",
    "            p = epoch_for_calc/tot_epochs_for_calc\n",
    "\n",
    "            self.adv_param = 2/(1 + math.exp(-self.gamma*p)) - 1\n",
    "        else:\n",
    "            self.use_adv = False\n",
    "\n",
    "    def forward(self, pred_info, labels, compute_adv_loss=True, print_=False):\n",
    "        lrec = self.rec_weight * self.rec_loss(ori_embeds=pred_info['text'], model_embeds=pred_info['recon_embeds'],\n",
    "                         embed_l=pred_info['text_l'])\n",
    "        lrec_topic = self.rec_weight * self.rec_loss(ori_embeds=pred_info['topic'], model_embeds=pred_info['topic_recon_embeds'],\n",
    "                                                 embed_l=pred_info['topic_l'])\n",
    "\n",
    "        ltrans = self.trans_loss(W=pred_info['W'])\n",
    "        llabel = self.stance_loss(pred_info['stance_pred'], labels)\n",
    "        ladv = torch.tensor(0)\n",
    "        adversarial_loss = torch.tensor(0)\n",
    "        if self.use_cuda:\n",
    "            ladv = ladv.to('cuda')\n",
    "            adversarial_loss = adversarial_loss.to('cuda')\n",
    "        if compute_adv_loss:        #Ladv is computed only on the train dataset else it is left as 0.\n",
    "            ladv = self.topic_loss(pred_info['adv_pred'], pred_info['topic_i'])\n",
    "            if self.rho_adv:\n",
    "                adversarial_loss = self.adv_param * self.topic_loss(pred_info['adv_pred_'], pred_info['topic_i'])\n",
    "            else:\n",
    "                adversarial_loss = self.topic_loss(pred_info['adv_pred_'], pred_info['topic_i'])\n",
    "\n",
    "        if print_:\n",
    "            print(\"lrec - {}, lrec_topic - {}, ltrans - {}, llabel - {}, ladv - {}\".format(lrec, lrec_topic, ltrans, llabel, ladv))\n",
    "\n",
    "        self.i += 1\n",
    "        if self.use_adv:\n",
    "            if self.i % 100 == 0:\n",
    "                print(\"loss: {:.4f} + {:.4f} + {:.4f} - {:.4f}; adv: {:.4f}\".format(lrec.item(), ltrans.item(), llabel.item(),\n",
    "                                                   (self.adv_param * ladv).item(), ladv))\n",
    "            return lrec + lrec_topic + ltrans + llabel - self.adv_param * ladv, adversarial_loss\n",
    "        else:\n",
    "            if self.i % 100 == 0:\n",
    "                print(\"loss: {:.4f} +  {:.4f} + {:.4f}; adv: {:.4f}\".format(lrec.item(), ltrans.item(), llabel.item(),\n",
    "                                                     ladv))\n",
    "            return lrec + lrec_topic + ltrans + llabel, adversarial_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e023d981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pickle, json\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "class StanceData(Dataset):\n",
    "    '''\n",
    "    Holds the stance dataset.\n",
    "    '''\n",
    "    def __init__(self, data_name, vocab_name, topic_name=None, name='',\n",
    "                 max_sen_len=10, max_tok_len=200, max_top_len=5, binary=False,\n",
    "                 pad_val=0, is_bert=False, add_special_tokens=True, use_tar_in_twe=False):\n",
    "        self.data_name = data_name\n",
    "        self.data_file = pd.read_csv(data_name)\n",
    "        if vocab_name is not None:\n",
    "            self.word2i = pickle.load(open(vocab_name, 'rb'))\n",
    "        self.name = name\n",
    "        self.max_sen_len = max_sen_len\n",
    "        self.max_tok_len = max_tok_len\n",
    "        self.max_top_len = max_top_len\n",
    "        self.binary = binary\n",
    "        self.pad_value = pad_val\n",
    "        self.topic2i = pickle.load(open(topic_name, 'rb')) if topic_name is not None else dict()\n",
    "        self.is_bert = is_bert\n",
    "        self.add_special_tokens = add_special_tokens\n",
    "        self.tar_in_twe = ('target_in_tweet' in self.data_file.columns)\n",
    "        self.use_tar_in_twe = use_tar_in_twe\n",
    "\n",
    "        if self.is_bert:\n",
    "            self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        self.preprocess_data()\n",
    "\n",
    "        if self.is_bert:\n",
    "            # filter unlabeled examples for Twitter\n",
    "            self.data_file = self.data_file.loc[self.data_file['label'] != 3]\n",
    "            self.data_file.reset_index(inplace=True)  # reset the index so we can access correctly later\n",
    "\n",
    "    def process_bert(self):\n",
    "        print(\"processing BERT\")\n",
    "        topic_str_lst = []\n",
    "        text_str_lst = []\n",
    "        for i in self.data_file.index:\n",
    "            row = self.data_file.iloc[i]\n",
    "            num_sens = 1\n",
    "            if 'topic_str' in self.data_file.columns:\n",
    "                ori_topic = row['topic_str']\n",
    "            else:\n",
    "                ori_topic = ' '.join(json.loads(row['topic']))\n",
    "                topic_str_lst.append(ori_topic)\n",
    "\n",
    "            if 'text_s' in self.data_file.columns:\n",
    "                ori_text = row['text_s']\n",
    "            else:\n",
    "                ori_text = ' '.join(sum(json.loads(row['text']), []))\n",
    "                text_str_lst.append(ori_text)\n",
    "\n",
    "            text_topic = self.tokenizer(ori_text, ori_topic, padding='max_length', max_length=int(self.max_tok_len),\n",
    "                                        return_token_type_ids=True,\n",
    "                                        return_attention_mask=True)\n",
    "            text = self.tokenizer(ori_text, add_special_tokens=self.add_special_tokens,\n",
    "                                  max_length=int(self.max_tok_len), padding='max_length')\n",
    "            topic = self.tokenizer(ori_topic, add_special_tokens=self.add_special_tokens,\n",
    "                                   max_length=int(self.max_top_len), padding='max_length')\n",
    "            self.data_file.at[i, 'text_idx'] = text['input_ids']\n",
    "            self.data_file.at[i, 'ori_text'] = ori_text\n",
    "            self.data_file.at[i, 'topic_idx'] = topic['input_ids']\n",
    "            self.data_file.at[i, 'num_sens'] = num_sens\n",
    "            self.data_file.at[i, 'text_topic_idx'] = text_topic['input_ids']\n",
    "            self.data_file.at[i, 'token_type_ids'] = text_topic['token_type_ids']\n",
    "            self.data_file.at[i, 'attention_mask'] = text_topic['attention_mask']\n",
    "        print(\"...finished pre-processing for BERT\")\n",
    "        if 'topic_str' not in self.data_file.columns:\n",
    "            self.data_file['topic_str'] = topic_str_lst\n",
    "\n",
    "        if 'text_s' not in self.data_file.columns:\n",
    "            self.data_file['text_s'] = text_str_lst\n",
    "        return\n",
    "\n",
    "\n",
    "    def process_nonbert(self):\n",
    "        # Creating topic_string from tokenized topic column for twitter dataset\n",
    "        if 'topic_str' not in self.data_file.columns:\n",
    "            add_topic_string = True\n",
    "        else:\n",
    "            add_topic_string = False\n",
    "\n",
    "        for i in self.data_file.index:\n",
    "            row = self.data_file.iloc[i]\n",
    "\n",
    "            # Tokenized text in the form of [[tokenized sentence 1],[tokenized sent 2],...].\n",
    "            # In twitter data it is a 2 D array with [[tokenized text]].\n",
    "            ori_text = json.loads(row['text'])\n",
    "            # Tokenized topic array - 1D array with tokenized topic\n",
    "            ori_topic = json.loads(row['topic'])\n",
    "\n",
    "            # index text & topic\n",
    "            text = [[self.get_index(w) for w in s] for s in ori_text]\n",
    "            topic = [self.get_index(w) for w in ori_topic][:self.max_top_len]\n",
    "\n",
    "            text = reduce(lambda x, y: x + y, text)\n",
    "            text = text[:self.max_tok_len]\n",
    "            text_lens = len(text)  # compute combined text len\n",
    "            num_sens = 1\n",
    "            text_mask = [1] * text_lens\n",
    "\n",
    "            while len(text) < self.max_tok_len:\n",
    "                text.append(self.pad_value)\n",
    "                text_mask.append(0)\n",
    "\n",
    "            # compute topic len\n",
    "            topic_lens = len(topic)  # get len (before padding)\n",
    "            topic_mask = [1] * topic_lens\n",
    "\n",
    "            # pad topic\n",
    "            while len(topic) < self.max_top_len:\n",
    "                topic.append(self.pad_value)\n",
    "                topic_mask.append(0)\n",
    "\n",
    "            if 'text_s' in self.data_file.columns:\n",
    "                ori_text_ = row['text_s']\n",
    "            else:\n",
    "                ori_text_ = ' '.join([' '.join(ti) for ti in ori_text])\n",
    "\n",
    "            if add_topic_string:\n",
    "                self.data_file.at[i, 'topic_str'] = ' '.join(ori_topic)\n",
    "\n",
    "            self.data_file.at[i, 'text_idx'] = text\n",
    "            self.data_file.at[i, 'topic_idx'] = topic\n",
    "            self.data_file.at[i, 'text_l'] = text_lens\n",
    "            self.data_file.at[i, 'topic_l'] = topic_lens\n",
    "            self.data_file.at[i, 'ori_text'] = ori_text_\n",
    "            self.data_file.at[i, 'num_sens'] = num_sens\n",
    "            self.data_file.at[i, 'text_mask'] = text_mask\n",
    "            self.data_file.at[i, 'topic_mask'] = topic_mask\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        print('preprocessing data {} ...'.format(self.data_name))\n",
    "\n",
    "        self.data_file['text_idx'] = [[] for _ in range(len(self.data_file))]\n",
    "        self.data_file['topic_idx'] = [[] for _ in range(len(self.data_file))]\n",
    "        self.data_file['text_topic_idx'] = [[] for _ in range(len(self.data_file))]\n",
    "        self.data_file['token_type_ids'] = [[] for _ in range(len(self.data_file))]\n",
    "        self.data_file['text_l'] = 0\n",
    "        self.data_file['ori_text'] = ''\n",
    "        self.data_file['topic_l'] = 0\n",
    "        self.data_file['num_sens'] = 0\n",
    "        self.data_file['text_mask'] = [[] for _ in range(len(self.data_file))]\n",
    "        self.data_file['topic_mask'] = [[] for _ in range(len(self.data_file))]\n",
    "\n",
    "        if self.is_bert:\n",
    "            self.process_bert()\n",
    "        else:\n",
    "            self.process_nonbert()\n",
    "\n",
    "        print(\"... finished preprocessing\")\n",
    "\n",
    "    def get_index(self, word):\n",
    "        return self.word2i[word] if word in self.word2i else len(self.word2i)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_file)\n",
    "\n",
    "    def __getitem__(self, idx, corpus=None):\n",
    "        row = self.data_file.iloc[idx]\n",
    "\n",
    "        l  = int(row['label'])\n",
    "\n",
    "        if self.tar_in_twe and self.use_tar_in_twe:\n",
    "            tar_in_twe_value = row['target_in_tweet']\n",
    "        else:\n",
    "            tar_in_twe_value = None\n",
    "\n",
    "        sample = {'text': row['text_idx'], 'topic': row['topic_idx'],\n",
    "                  'label': l,\n",
    "                  'txt_l': row['text_l'], 'top_l': row['topic_l'],\n",
    "                  'ori_topic': row['topic_str'],\n",
    "                  'ori_text': row['ori_text'],\n",
    "                  'text_mask': row['text_mask'],\n",
    "                  'num_s': row['num_sens'],\n",
    "                  'seen': row['seen?'],\n",
    "                  }\n",
    "        if self.is_bert and not self.add_special_tokens:\n",
    "            sample['text_topic'] = row['text_topic_idx']\n",
    "            sample['token_type_ids'] = row['token_type_ids']\n",
    "            sample['attention_mask'] = row['attention_mask']\n",
    "        else:\n",
    "            sample['topic_i'] = self.topic2i.get(row['topic'], 0)\n",
    "            sample['topic_mask'] = row['topic_mask']\n",
    "            sample['target_in_tweet'] = tar_in_twe_value\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46e5b463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Using cached huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\aishw\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp39-cp39-win_amd64.whl (3.3 MB)\n",
      "     ---------------------------------------- 3.3/3.3 MB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\aishw\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\aishw\\anaconda3\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: filelock in c:\\users\\aishw\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aishw\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aishw\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in c:\\users\\aishw\\anaconda3\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aishw\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\aishw\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\aishw\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aishw\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\aishw\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aishw\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aishw\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1934284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_vectors(vecfile, dim=300, unk_rand=True, seed=0):\n",
    "    '''\n",
    "    Loads saved vectors;\n",
    "    :param vecfile: the name of the file to load the vectors from.\n",
    "    :return: a numpy array of all the vectors.\n",
    "    '''\n",
    "    vecs = np.load(vecfile)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    if unk_rand:\n",
    "        vecs = np.vstack((vecs, np.random.randn(dim))) # <unk> -> V-2\n",
    "    else:\n",
    "        vecs = np.vstack((vecs, np.zeros(dim))) # <unk> -> V - 2\n",
    "    vecs = np.vstack((vecs, np.zeros(dim))) # pad -> V-1\n",
    "    vecs = vecs.astype(float, copy=False)\n",
    "\n",
    "    return vecs\n",
    "\n",
    "def prepare_batch(sample_batched, **kwargs):\n",
    "    '''\n",
    "    Prepares a batch of data to be used in training or evaluation. Includes the text reversed.\n",
    "    :param sample_batched: a list of dictionaries, where each is a sample\n",
    "    :return: a dictionary containing:\n",
    "            a tensor of all the text instances,\n",
    "            a tensor of all topic instances,\n",
    "            a list of labels for the text,topic instances\n",
    "            a list of the text lengths\n",
    "            a list of the topic lengths\n",
    "            a list with the original texts\n",
    "            a list with the original topics\n",
    "            AND (depending on flags)\n",
    "            a tensor of the inputs in the format CLS text SEP topic SEP (for Bert)\n",
    "            a tensor of the token type ids (for Bert)\n",
    "            a tensor with the generalized topic representations\n",
    "    '''\n",
    "    text_lens = np.array([b['txt_l'] for b in sample_batched])\n",
    "    topic_batch = torch.tensor([b['topic'] for b in sample_batched])\n",
    "    labels = [b['label'] for b in sample_batched]\n",
    "    top_lens = [b['top_l'] for b in sample_batched]\n",
    "\n",
    "    raw_text_batch = [b['ori_text'] for b in sample_batched]\n",
    "    raw_top_batch = [b['ori_topic'] for b in sample_batched]\n",
    "\n",
    "    text_batch = torch.tensor([b['text'] for b in sample_batched])\n",
    "\n",
    "    args = {'text': text_batch, 'topic': topic_batch, 'labels': labels,\n",
    "            'txt_l': text_lens, 'top_l': top_lens,\n",
    "            'ori_text': raw_text_batch, 'ori_topic': raw_top_batch}\n",
    "\n",
    "    if 'text_topic' in sample_batched[0]:\n",
    "        args['text_topic_batch'] = torch.tensor([b['text_topic'] for b in sample_batched])\n",
    "        args['token_type_ids'] = torch.tensor([b['token_type_ids'] for b in sample_batched])\n",
    "        args['attention_mask'] = torch.tensor([b['attention_mask'] for b in sample_batched])\n",
    "\n",
    "    if 'topic_rep_id' in sample_batched[0]:\n",
    "        args['topic_rep_ids'] = torch.tensor([b['topic_rep_id'] for b in sample_batched])\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def prepare_batch_adv(sample_batched, **kwargs):\n",
    "    args = prepare_batch(sample_batched, **kwargs)\n",
    "\n",
    "    txt_mask = [b['text_mask'] for b in sample_batched]\n",
    "    args['txt_mask'] = txt_mask\n",
    "\n",
    "    top_mask = [b['topic_mask'] for b in sample_batched]\n",
    "    args['top_mask'] = top_mask\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "class DataSampler:\n",
    "    '''\n",
    "    A sampler for a dataset. Can get samples of differents sizes.\n",
    "    Is iterable. By default shuffles the data each time all the data\n",
    "    has been used through iteration.\n",
    "    '''\n",
    "    def __init__(self, data, batch_size, shuffle=True):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        random.seed(0)\n",
    "\n",
    "        self.indices = list(range(len(data)))\n",
    "        if shuffle:\n",
    "            random.shuffle(self.indices)\n",
    "        self.batch_num = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def num_batches(self):\n",
    "        return len(self.data) / float(self.batch_size)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.indices = list(range(len(self.data)))\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.indices)\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.indices != []:\n",
    "            idxs = self.indices[:self.batch_size]\n",
    "            batch = [self.data.__getitem__(i) for i in idxs]\n",
    "            self.indices = self.indices[self.batch_size:]\n",
    "            return batch\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "    def get(self):\n",
    "        self.reset()\n",
    "        return self.__next__()\n",
    "\n",
    "    def reset(self):\n",
    "        self.indices = list(range(len(self.data)))\n",
    "        if self.shuffle: random.shuffle(self.indices)\n",
    "\n",
    "\n",
    "def setup_helper_bicond(args, use_cuda):\n",
    "    if use_cuda:\n",
    "        txt_E= args['txt_E'].to('cuda')  # (B,T,E)\n",
    "        top_E = args['top_E'].to('cuda')  # (B,C,E)\n",
    "        txt_l = torch.tensor(args['txt_l']).to('cuda')  # (B, S)\n",
    "        top_l = torch.tensor(args['top_l']).to('cuda')  # (B)\n",
    "    else:\n",
    "        txt_E = args['txt_E']  # (B,T,E)\n",
    "        top_E = args['top_E']  # (B,C,E)\n",
    "        txt_l = torch.tensor(args['txt_l'])\n",
    "        top_l = torch.tensor(args['top_l'])\n",
    "    return txt_E, top_E, txt_l, top_l\n",
    "\n",
    "\n",
    "def setup_helper_adv(args, use_cuda):\n",
    "    if use_cuda:\n",
    "        txt_E= args['txt_E'].to('cuda')  # (B,T,E)\n",
    "        top_E = args['top_E'].to('cuda')  # (B,C,E)\n",
    "    else:\n",
    "        txt_E = args['txt_E']  # (B,T,E)\n",
    "        top_E = args['top_E']  # (B,C,E)\n",
    "\n",
    "    device = 'cuda' if use_cuda else 'cpu'\n",
    "\n",
    "    txt_l = torch.tensor(args['txt_l'], device=device)  # (B, S)\n",
    "    top_l = torch.tensor(args['top_l'], device=device) # (B)\n",
    "    txt_mask = torch.tensor(args['txt_mask'], device=device) # (B, T)\n",
    "    top_mask = torch.tensor(args['top_mask'], device=device) # (B, C)\n",
    "\n",
    "    return txt_E, top_E, txt_l, top_l, txt_mask, top_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8397663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, sys\n",
    "import torch.nn as nn\n",
    "import baseline_model_layers as bml\n",
    "from transformers import  BertForSequenceClassification\n",
    "\n",
    "\n",
    "class BiCondLSTMModel(torch.nn.Module):\n",
    "    '''\n",
    "    Bidirectional Coniditional Encoding LSTM (Augenstein et al, 2016, EMNLP)\n",
    "    Single layer bidirectional LSTM where initial states are from the topic encoding.\n",
    "    Topic is also with a bidirectional LSTM. Prediction done with a single layer FFNN with\n",
    "    tanh then softmax, to use cross-entropy loss.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, hidden_dim, embed_dim, input_dim, drop_prob=0, num_layers=1, num_labels=3,\n",
    "                 use_cuda=False):\n",
    "        super(BiCondLSTMModel, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        self.bilstm = bml.BiCondLSTMLayer(hidden_dim, embed_dim, input_dim, drop_prob, num_layers,\n",
    "                                      use_cuda=use_cuda)\n",
    "        self.dropout = nn.Dropout(p=drop_prob)  # so we can have dropouts on last layer\n",
    "        self.pred_layer = bml.PredictionLayer(input_size=2 * num_layers * hidden_dim,\n",
    "                                          output_size=self.num_labels,\n",
    "                                          pred_fn=nn.Tanh(), use_cuda=use_cuda)  # This is BiCond specific\n",
    "\n",
    "\n",
    "    def forward(self, text, topic, text_l, topic_l):\n",
    "\n",
    "        text = text.transpose(0, 1)  # (T, B, E)\n",
    "        topic = topic.transpose(0, 1)  # (C,B,E)\n",
    "\n",
    "        _, combo_fb_hn, _, _ = self.bilstm(text, topic, topic_l, text_l)\n",
    "\n",
    "        # dropout\n",
    "        combo_fb_hn = self.dropout(combo_fb_hn)  # (B, H*N, dir*N_layers)\n",
    "\n",
    "        y_pred = self.pred_layer(combo_fb_hn)  # (B, 2)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class AdversarialBasic(torch.nn.Module):\n",
    "    def __init__(self, enc_params, enc_type, stance_dim, topic_dim, num_labels, num_topics,\n",
    "                 drop_prob=0.0, use_cuda=False):\n",
    "        super(AdversarialBasic, self).__init__()\n",
    "        self.enc_type = enc_type\n",
    "        self.use_cuda = use_cuda\n",
    "        self.hidden_dim = enc_params['h']\n",
    "        self.embed_dim = enc_params['embed_dim']\n",
    "        self.stance_dim = stance_dim\n",
    "        self.num_labels = num_labels\n",
    "        self.num_topics = num_topics\n",
    "\n",
    "        if self.enc_type == 'bicond':\n",
    "            self.enc = bml.BiCondLSTMLayer(hidden_dim=self.hidden_dim, embed_dim=self.embed_dim, input_dim=self.embed_dim,\n",
    "                                           drop_prob=enc_params['drop_prob'], num_layers=1, use_cuda=use_cuda)\n",
    "            self.att_layer = bml.ScaledDotProductAttention(input_dim=2*self.hidden_dim, use_cuda=self.use_cuda)\n",
    "        else:\n",
    "            print(\"ERROR: invalid encoder type. exiting\")\n",
    "            sys.exit(1)\n",
    "        self.in_dropout = nn.Dropout(p=drop_prob)\n",
    "        self.out_dropout = nn.Dropout(p=drop_prob)\n",
    "\n",
    "        self.recon_layer = bml.ReconstructionLayer(hidden_dim=self.hidden_dim, embed_dim=self.embed_dim,\n",
    "                                                   use_cuda=self.use_cuda)\n",
    "\n",
    "        self.topic_recon_layer = bml.ReconstructionLayer(hidden_dim=self.hidden_dim, embed_dim=self.embed_dim, use_cuda=self.use_cuda)\n",
    "        self.trans_layer = bml.TransformationLayer(input_size=2*self.hidden_dim)\n",
    "\n",
    "        multiplier = 4\n",
    "        self.stance_classifier = bml.TwoLayerFFNNLayer(input_dim=multiplier*self.hidden_dim, hidden_dim=stance_dim,\n",
    "                                                       out_dim=self.num_labels, nonlinear_fn=nn.ReLU())\n",
    "        self.topic_classifier = bml.TwoLayerFFNNLayer(input_dim=2*self.hidden_dim, hidden_dim=topic_dim,\n",
    "                                                       out_dim=self.num_topics, nonlinear_fn=nn.ReLU())\n",
    "\n",
    "    def forward(self, text, topic, text_l, topic_l, text_mask=None, topic_mask=None):\n",
    "        # text: (B, T, E), topic: (B, C, E), text_l: (B), topic_l: (B), text_mask: (B, T), topic_mask: (B, C)\n",
    "\n",
    "        # apply dropout on the input\n",
    "        dropped_text = self.in_dropout(text)\n",
    "\n",
    "        # encode the text\n",
    "        if self.enc_type == 'bicond':\n",
    "            output, _, last_top_hn, topic_output = self.enc(dropped_text.transpose(0, 1),\n",
    "                                              topic.transpose(0, 1),\n",
    "                                              topic_l, text_l)\n",
    "            output = output.transpose(0, 1)     #output represents the token level text encodings of size (B,T,2*H)\n",
    "            topic_output = topic_output.transpose(0, 1)   #Token levek topic embeddings of size (B, C, 2*H)\n",
    "            last_top_hn = last_top_hn.transpose(0, 1).reshape(-1, 2*self.hidden_dim)        #(B, 2*H)\n",
    "            att_vecs = self.att_layer(output, last_top_hn)      #(B, 2H)\n",
    "\n",
    "\n",
    "        # reconstruct the original embeddings\n",
    "        recon_embeds = self.recon_layer(output, text_mask) #(B, L, E)\n",
    "        # reconstruct topic embeddings\n",
    "        topic_recon_embeds = self.topic_recon_layer(topic_output, topic_mask)\n",
    "\n",
    "        # transform the representation\n",
    "        trans_reps = self.trans_layer(att_vecs) #(B, 2H)\n",
    "\n",
    "        trans_reps = self.out_dropout(trans_reps)  # adding dropout\n",
    "        last_top_hn = self.out_dropout(last_top_hn)\n",
    "\n",
    "        # stance prediction\n",
    "        # added topic input to stance classifier\n",
    "        stance_input = torch.cat((trans_reps, last_top_hn), 1)      #(B, 4H)\n",
    "        stance_preds = self.stance_classifier(stance_input)\n",
    "\n",
    "        # topic prediction\n",
    "        topic_preds = self.topic_classifier(trans_reps)\n",
    "        topic_preds_ = self.topic_classifier(trans_reps.detach())\n",
    "\n",
    "        pred_info = {'text': text, 'text_l': text_l,\n",
    "                     'topic': topic, 'topic_l': topic_l,\n",
    "                     'adv_pred': topic_preds, 'adv_pred_':topic_preds_, 'stance_pred': stance_preds,\n",
    "                     'topic_recon_embeds': topic_recon_embeds, 'recon_embeds': recon_embeds}\n",
    "\n",
    "        return pred_info\n",
    "\n",
    "\n",
    "class JointSeqBERTLayer(torch.nn.Module):\n",
    "    def __init__(self, num_labels=3, use_cuda=False):\n",
    "        super(JointSeqBERTLayer, self).__init__()\n",
    "\n",
    "        self.num_labels = num_labels\n",
    "        self.use_cuda = use_cuda\n",
    "        self.bert_layer = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        self.dim = 768\n",
    "        if self.use_cuda:\n",
    "            self.bert_layer = self.bert_layer.to('cuda')\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        output = self.bert_layer(input_ids=kwargs['text_topic_batch'].to('cuda'),\n",
    "                                 token_type_ids=kwargs['token_type_ids'].to('cuda'),\n",
    "                                 attention_mask=kwargs['attention_mask'].to('cuda'))\n",
    "        return output[0]\n",
    "\n",
    "\n",
    "class WordEmbedLayer(torch.nn.Module):\n",
    "    def __init__(self, vecs, static_embeds=True, use_cuda=False):\n",
    "        super(WordEmbedLayer, self).__init__()\n",
    "        vec_tensor = torch.tensor(vecs)\n",
    "\n",
    "        self.embeds = nn.Embedding.from_pretrained(vec_tensor, freeze=static_embeds)\n",
    "\n",
    "        self.dim = vecs.shape[1]\n",
    "        print(\"Input layer embedding size -  \", self.dim)\n",
    "        self.vocab_size = float(vecs.shape[0])\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        embed_args = {'txt_E': self.embeds(kwargs['text']).type(torch.FloatTensor),  # (B, T, E)\n",
    "                      'top_E': self.embeds(kwargs['topic']).type(torch.FloatTensor)}  # (B, C, E)\n",
    "        return embed_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1aa9fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, math\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn\n",
    "\n",
    "\n",
    "class TwoLayerFFNNLayer(torch.nn.Module):\n",
    "    '''\n",
    "    2-layer FFNN with specified nonlinear function\n",
    "    must be followed with some kind of prediction layer for actual prediction\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, out_dim, nonlinear_fn):\n",
    "        super(TwoLayerFFNNLayer, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "        self.model = nn.Sequential(nn.Linear(input_dim, hidden_dim),\n",
    "                                   nonlinear_fn,\n",
    "                                   nn.Linear(hidden_dim, out_dim))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n",
    "\n",
    "class PredictionLayer(torch.nn.Module):\n",
    "    '''\n",
    "    Predicition layer. linear projection followed by the specified functions\n",
    "    ex: pass pred_fn=nn.Tanh()\n",
    "    '''\n",
    "    def __init__(self, input_size, output_size, pred_fn, use_cuda=False):\n",
    "        super(PredictionLayer, self).__init__()\n",
    "\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "        self.input_dim = input_size\n",
    "        self.output_dim = output_size\n",
    "        self.pred_fn = pred_fn\n",
    "\n",
    "        self.model = nn.Sequential(nn.Linear(self.input_dim, self.output_dim, bias=False))\n",
    "\n",
    "        if self.use_cuda:\n",
    "            self.model = self.model.to('cuda')#cuda()\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        return self.model(input_data)\n",
    "\n",
    "\n",
    "class BiCondLSTMLayer(torch.nn.Module):\n",
    "    '''\n",
    "    Bidirection Conditional Encoding (Augenstein et al. 2016 EMNLP).\n",
    "    Bidirectional LSTM with initial states from topic encoding.\n",
    "    Topic encoding is also a bidirectional LSTM.\n",
    "    '''\n",
    "    def __init__(self, hidden_dim, embed_dim, input_dim, drop_prob=0, num_layers=1, use_cuda=False):\n",
    "        super(BiCondLSTMLayer, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "        self.topic_lstm = nn.LSTM(input_dim, self.hidden_dim, bidirectional=True)\n",
    "        self.text_lstm = nn.LSTM(self.embed_dim, self.hidden_dim, bidirectional=True)\n",
    "\n",
    "    def forward(self, txt_e, top_e, top_l, txt_l):\n",
    "        ####################\n",
    "        # txt_e = (Lx, B, E), top_e = (Lt, B, E), top_l=(B), txt_l=(B)\n",
    "        ########################\n",
    "        p_top_embeds = rnn.pack_padded_sequence(top_e, top_l, enforce_sorted=False)\n",
    "\n",
    "        self.topic_lstm.flatten_parameters()\n",
    "\n",
    "        # feed topic\n",
    "        topic_output, last_top_hn_cn = self.topic_lstm(p_top_embeds)  # (seq_ln, B, 2*H),((2, B, H), (2, B, H))\n",
    "        last_top_hn = last_top_hn_cn[0]  # LSTM\n",
    "        padded_topic_output, _ = rnn.pad_packed_sequence(topic_output,total_length=top_e.shape[0])\n",
    "\n",
    "        p_text_embeds = rnn.pack_padded_sequence(txt_e, txt_l, enforce_sorted=False)\n",
    "        self.text_lstm.flatten_parameters()\n",
    "\n",
    "        # feed text conditioned on topic\n",
    "        output, (txt_last_hn, _)  = self.text_lstm(p_text_embeds, last_top_hn_cn) # (2, B, H)\n",
    "        txt_fw_bw_hn = txt_last_hn.transpose(0, 1).reshape((-1, 2 * self.hidden_dim))\n",
    "        padded_output, _ = rnn.pad_packed_sequence(output, total_length=txt_e.shape[0])\n",
    "        return padded_output, txt_fw_bw_hn, last_top_hn, padded_topic_output\n",
    "\n",
    "\n",
    "class ScaledDotProductAttention(torch.nn.Module):\n",
    "    def __init__(self, input_dim, use_cuda=False):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        self.scale = math.sqrt(2 * self.input_dim)\n",
    "\n",
    "    def forward(self, inputs, query):\n",
    "        # inputs = (B, L, 2*H), query = (B, 2*H), last_hidden=(B, 2*H)\n",
    "        sim = torch.einsum('blh,bh->bl', inputs, query) / self.scale  # (B, L)\n",
    "        att_weights = nn.functional.softmax(sim, dim=1)  # (B, L)\n",
    "        context_vec = torch.einsum('blh,bl->bh', inputs, att_weights)  # (B, 2*H)\n",
    "        return context_vec\n",
    "    \n",
    "\n",
    "class TransformationLayer(torch.nn.Module):\n",
    "    '''\n",
    "    Linear transformation layer\n",
    "    '''\n",
    "    def __init__(self, input_size):\n",
    "        super(TransformationLayer, self).__init__()\n",
    "\n",
    "        self.dim = input_size\n",
    "\n",
    "        self.W = torch.empty((self.dim, self.dim))\n",
    "        self.W = nn.Parameter(nn.init.xavier_normal_(self.W)) # (D, D)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # text: (B, D)\n",
    "        return torch.einsum('bd,dd->bd', text, self.W)\n",
    "\n",
    "\n",
    "class ReconstructionLayer(torch.nn.Module):\n",
    "    '''\n",
    "    Embedding reconstruction layer\n",
    "    '''\n",
    "    def __init__(self, hidden_dim, embed_dim, use_cuda=False):\n",
    "        super(ReconstructionLayer, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embed_dim=embed_dim\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "        self.recon_W = torch.empty((2 * self.hidden_dim, self.embed_dim),\n",
    "                                   device=('cuda' if self.use_cuda else 'cpu'))\n",
    "        self.recon_w = nn.Parameter(nn.init.xavier_normal_(self.recon_W))\n",
    "        self.recon_b = torch.empty((self.embed_dim, 1), device=('cuda' if self.use_cuda else 'cpu'))\n",
    "        self.recon_b = nn.Parameter(nn.init.xavier_normal_(self.recon_b)).squeeze(1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, text_output, text_mask):\n",
    "        # text_output: (B, T, H), text_mask: (B, T)\n",
    "        recon_embeds = self.tanh(torch.einsum('blh,he->ble', text_output, self.recon_w) + self.recon_b)  # (B,L,E)\n",
    "        recon_embeds = torch.einsum('ble,bl->ble', recon_embeds, text_mask)\n",
    "\n",
    "        return recon_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56b661b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --mode MODE [--config_file CONFIG_FILE]\n",
      "                             [--trn_data TRN_DATA] [--dev_data DEV_DATA]\n",
      "                             [--name NAME] [-p NUM_WARM]\n",
      "                             [--topics_vocab TOPICS_VOCAB]\n",
      "                             [--score_key SCORE_KEY]\n",
      "                             [--saved_model_file_name SAVED_MODEL_FILE_NAME]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --mode\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aishw\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3377: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import torch, sys, os, argparse, time\n",
    "sys.path.append('./modeling')\n",
    "import baseline_models as bm\n",
    "import data_utils, model_utils, datasets\n",
    "import loss_fn as lf\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import copy\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "SEED = 0\n",
    "LOCAL = True\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "def train(model_handler, num_epochs, verbose=True, dev_data=None, num_warm=0, phases=False, is_adv=True):\n",
    "    '''\n",
    "    Trains the given model using the given data for the specified\n",
    "    number of epochs. Prints training loss and evaluation starting\n",
    "    after 10 epochs. Saves at most 10 checkpoints plus a final one.\n",
    "    :param model_handler: a holder with a model and data to be trained.\n",
    "                            Assuming the model is a pytorch model.\n",
    "    :param num_epochs: the number of epochs to train the model for.\n",
    "    :param verbose: whether or not to print train results while training.\n",
    "                    Default (True): do print intermediate results.\n",
    "    '''\n",
    "    trn_scores_dict = {}\n",
    "    dev_scores_dict = {}\n",
    "    for epoch in range(num_epochs):\n",
    "        if is_adv:\n",
    "            learning_rate = model_handler.get_learning_rate()\n",
    "        if phases:\n",
    "            model_handler.train_step_phases()\n",
    "        else:\n",
    "            model_handler.train_step()\n",
    "\n",
    "        if epoch >= num_warm:\n",
    "            if verbose:\n",
    "                # print training loss and training (& dev) scores, ignores the first few epochs\n",
    "                print(\"training loss: {}\".format(model_handler.loss))\n",
    "                # eval model on training data\n",
    "                trn_scores = eval_helper(model_handler, data_name='TRAIN')\n",
    "                trn_scores_dict[epoch] = copy.deepcopy(trn_scores)\n",
    "                if is_adv:\n",
    "                    trn_scores_dict[epoch].update({'lr': copy.deepcopy(learning_rate),\n",
    "                                                   'rho': copy.deepcopy(model_handler.loss_function.adv_param)})\n",
    "                # update best scores\n",
    "                if dev_data is not None:\n",
    "                    dev_scores = eval_helper(model_handler, data_name='DEV',\n",
    "                                             data=dev_data)\n",
    "                    dev_scores_dict[epoch] = copy.deepcopy(dev_scores)\n",
    "                    model_handler.save_best(scores=dev_scores)\n",
    "                else:\n",
    "                    model_handler.save_best(scores=trn_scores)\n",
    "\n",
    "    print(\"TRAINED for {} epochs\".format(epoch))\n",
    "\n",
    "    # save final checkpoint\n",
    "    model_handler.save(num=\"FINAL\")\n",
    "\n",
    "    # print final training (& dev) scores\n",
    "    eval_helper(model_handler, data_name='TRAIN')\n",
    "    if dev_data is not None:\n",
    "        eval_helper(model_handler,  data_name='DEV', data=dev_data)\n",
    "    # Can uncomment to save epoch_level_scores\n",
    "    #save_epoch_level_results_to_csv(trn_scores_dict, dev_scores_dict, model_handler.result_path, model_handler.name, is_adv)\n",
    "\n",
    "\n",
    "def save_epoch_level_results_to_csv(trn_scores_dict, dev_scores_dict, output_path, name, is_adv):\n",
    "    '''\n",
    "    Saves the results from the current epoch to a CSV file\n",
    "    :param trn_scores_dict: a dictionary containing training scores\n",
    "    :param dev_scores_dict: a dictionary containing dev set scores\n",
    "    :param output_path: the path for where to save the scores\n",
    "    :param name: the prefix for the file name\n",
    "    :param is_adv: whether or not the scores are from the adversarial  model\n",
    "    '''\n",
    "    dev_fscore_overall_list = []\n",
    "    dev_fscore_seen_list = []\n",
    "    dev_fscore_unseen_list = []\n",
    "    train_fscore_overall_list = []\n",
    "    train_fscore_seen_list = []\n",
    "    train_fscore_unseen_list = []\n",
    "    topic_fscore_list = []\n",
    "    learning_rate_list = []\n",
    "    rho_list = []\n",
    "    epochs = []\n",
    "    for key in trn_scores_dict.keys():\n",
    "        epochs.append(key)\n",
    "        if is_adv:\n",
    "            learning_rate_list.append(trn_scores_dict[key]['lr'])\n",
    "            rho_list.append(trn_scores_dict[key]['rho'])\n",
    "            topic_fscore_list.append(trn_scores_dict[key]['topic-f_macro'])\n",
    "        dev_fscore_overall_list.append(dev_scores_dict[key]['f_macro'])\n",
    "        dev_fscore_seen_list.append(dev_scores_dict[key]['f-1_macro'])\n",
    "        dev_fscore_unseen_list.append(dev_scores_dict[key]['f-0_macro'])\n",
    "        train_fscore_overall_list.append(trn_scores_dict[key]['f_macro'])\n",
    "        train_fscore_seen_list.append(trn_scores_dict[key]['f-1_macro'])\n",
    "        train_fscore_unseen_list.append(trn_scores_dict[key]['f-0_macro'])\n",
    "        \n",
    "    if is_adv:\n",
    "        df = pd.DataFrame(list(zip(epochs, learning_rate_list, rho_list, dev_fscore_overall_list, dev_fscore_seen_list,\n",
    "                                   dev_fscore_unseen_list, topic_fscore_list, train_fscore_overall_list,\n",
    "                                   train_fscore_seen_list,train_fscore_unseen_list)),\n",
    "                      columns=['Epoch', 'Learning Rate', 'Rho', 'Dev Fscore overall', 'Dev Fscore seen',\n",
    "                               'Dev Fscore unseen', 'Topic Fscore', 'Train Fscore overall', 'Train Fscore seen',\n",
    "                               'Train Fscore unseen'])\n",
    "    else:\n",
    "        df = pd.DataFrame(list(zip(epochs, dev_fscore_overall_list, dev_fscore_seen_list, dev_fscore_unseen_list,\n",
    "                               train_fscore_overall_list, train_fscore_seen_list, train_fscore_unseen_list)),\n",
    "                      columns=['Epoch', 'Dev Fscore overall', 'Dev Fscore seen', 'Dev Fscore unseen',\n",
    "                               'Train Fscore overall', 'Train Fscore seen', 'Train Fscore unseen'])\n",
    "    df.to_csv(\"{}{}_epoch_level_scores.csv\".format(output_path, name), index=False)\n",
    "\n",
    "\n",
    "def eval_helper(model_handler, data_name, data=None):\n",
    "    '''\n",
    "    Helper function for evaluating the model during training.\n",
    "    Can evaluate on all the data or just a subset of corpora.\n",
    "    :param model_handler: the holder for the model\n",
    "    :return: the scores from running on all the data\n",
    "    '''\n",
    "    # eval on full corpus\n",
    "    scores = model_handler.eval_and_print(data=data, data_name=data_name, class_wise=True)\n",
    "    return scores\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--mode', dest='mode', help='What to do', required=True)\n",
    "    parser.add_argument('--config_file', dest='config_file', help='Name of the cofig data file', required=False)\n",
    "    parser.add_argument('--trn_data', dest='trn_data', help='Name of the training data file', required=False)\n",
    "    parser.add_argument('--dev_data', dest='dev_data', help='Name of the dev data file', default=None, required=False)\n",
    "    parser.add_argument('--name', dest='name', help='something to add to the saved model name',\n",
    "                        required=False, default='')\n",
    "    parser.add_argument('-p', '--num_warm', help='Number of warm-up epochs', required=False,\n",
    "                        type=int, default=0)\n",
    "    parser.add_argument('--topics_vocab', dest='topics_vocab', help='Name of the topic file', required=False,\n",
    "                        type=str, default='twitter-topic.vocab.pkl')\n",
    "    parser.add_argument('--score_key', dest='score_key', help='Score key for optimization', required=False,\n",
    "                        default='f_macro')\n",
    "    parser.add_argument('--saved_model_file_name', dest='saved_model_file_name', required=False, default=None)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    ####################\n",
    "    # load config file #\n",
    "    ####################\n",
    "    with open(args.config_file, 'r') as f:\n",
    "        config = dict()\n",
    "        for l in f.readlines():\n",
    "            config[l.strip().split(\":\")[0]] = l.strip().split(\":\")[1]\n",
    "\n",
    "    ################\n",
    "    # load vectors #\n",
    "    ################\n",
    "    if not LOCAL:\n",
    "        vec_path = 'resources'\n",
    "    else:\n",
    "        vec_path = 'data/resources'     #Need to set path to vectors here\n",
    "\n",
    "    if 'bert' not in config['name']:\n",
    "\n",
    "        vec_name = config['vec_name']\n",
    "        vec_dim = int(config['vec_dim'])\n",
    "\n",
    "        vecs = data_utils.load_vectors('{}/{}.vectorsF.npy'.format(vec_path, vec_name),\n",
    "                                       dim=vec_dim, seed=SEED)\n",
    "\n",
    "    #############\n",
    "    # LOAD DATA #\n",
    "    #############\n",
    "    # load training data\n",
    "    vocab_name = '{}/{}.vocabF.pkl'.format(vec_path, vec_name)\n",
    "    data = datasets.StanceData(args.trn_data, vocab_name, topic_name='{}/{}'.format(vec_path, args.topics_vocab),\n",
    "                           pad_val=len(vecs) - 1,\n",
    "                           max_tok_len=int(config.get('max_tok_len', '200')),\n",
    "                           max_sen_len=int(config.get('max_sen_len', '10')),\n",
    "                           max_top_len=int(config.get('max_top_len', '5')))\n",
    "    \n",
    "    dataloader = data_utils.DataSampler(data,  batch_size=int(config['b']))\n",
    "\n",
    "    # load dev data if specified\n",
    "    if args.dev_data is not None:\n",
    "        dev_data = datasets.StanceData(args.dev_data, vocab_name, topic_name=None,\n",
    "                                       pad_val=len(vecs) - 1,\n",
    "                                       max_tok_len=int(config.get('max_tok_len', '200')),\n",
    "                                       max_sen_len=int(config.get('max_sen_len', '10')),\n",
    "                                       max_top_len=int(config.get('max_top_len', '5')),\n",
    "                                       use_tar_in_twe=('use_tar_in_twe' in config))\n",
    "\n",
    "        dev_dataloader = data_utils.DataSampler(dev_data, batch_size=int(config['b']), shuffle=False)\n",
    "\n",
    "    else:\n",
    "        dev_dataloader = None\n",
    "\n",
    "    # set the optimizer\n",
    "    if 'optimizer' not in config:\n",
    "        optim_fn = optim.Adam\n",
    "    else:\n",
    "        if config['optimizer'] == 'adamw':\n",
    "            optim_fn = optim.AdamW\n",
    "        elif config['optimizer'] == 'sgd':\n",
    "            optim_fn = optim.SGD\n",
    "        else:\n",
    "            print(\"ERROR with optimizer\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    lr = float(config.get('lr', '0.001'))\n",
    "    nl = 3\n",
    "    adv = False\n",
    "\n",
    "    # RUN\n",
    "    print(\"Using cuda?: {}\".format(use_cuda))\n",
    "\n",
    "    if 'bert' in config['name']:\n",
    "        batch_args = {'keep_sen': False}\n",
    "        setup_fn = data_utils.setup_helper_bert_ffnn\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        input_layer = None\n",
    "        model = bm.JointSeqBERTLayer(nl, use_cuda=use_cuda)\n",
    "\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "        num_training_steps = len(data) * int(config['epochs'])\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                    num_warmup_steps=0.1 * num_training_steps,\n",
    "                                                    num_training_steps=num_training_steps)\n",
    "\n",
    "        kwargs = {'model': model, 'embed_model': input_layer, 'dataloader': dataloader,\n",
    "                  'batching_fn': data_utils.prepare_batch,\n",
    "                  'batching_kwargs': batch_args, 'name': config['name'],\n",
    "                  'loss_function': loss_fn,\n",
    "                  'optimizer': optimizer,\n",
    "                  'scheduler': scheduler,\n",
    "                  'setup_fn': setup_fn,\n",
    "                  'fine_tune': (config.get('fine-tune', 'no') == 'yes')}\n",
    "\n",
    "        model_handler = model_utils.TorchModelHandler(use_cuda=use_cuda,\n",
    "                                                      checkpoint_path=config.get('ckp_path', 'data/checkpoints/'),\n",
    "                                                      result_path=config.get('res_path', 'data/gen-stance/'),\n",
    "                                                      use_score=args.score_key, save_ckp=args.save_ckp,\n",
    "                                                      **kwargs)\n",
    "\n",
    "    elif 'BiCond' in config['name']:\n",
    "        batch_args = {}\n",
    "        input_layer = bm.WordEmbedLayer(vecs=vecs, use_cuda=use_cuda)\n",
    "\n",
    "        setup_fn = data_utils.setup_helper_bicond\n",
    "\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        model = bm.BiCondLSTMModel(int(config['h']), embed_dim=input_layer.dim,\n",
    "                                   input_dim=(int(config['in_dim']) if 'in_dim' in config['name'] else input_layer.dim),\n",
    "                                   drop_prob=float(config['dropout']), use_cuda=use_cuda,\n",
    "                                   num_labels=nl)\n",
    "        o = optim_fn(model.parameters(), lr=lr)\n",
    "\n",
    "        bf = data_utils.prepare_batch\n",
    "\n",
    "        kwargs = {'model': model, 'embed_model': input_layer, 'dataloader': dataloader,\n",
    "                  'batching_fn': bf,\n",
    "                  'batching_kwargs': batch_args, 'name': config['name'] + args.name,\n",
    "                  'loss_function': loss_fn,\n",
    "                  'optimizer': o,\n",
    "                  'setup_fn': setup_fn,\n",
    "                  'blackout_start': int(config['blackout_start']),\n",
    "                  'blackout_stop': int(config['blackout_stop'])}\n",
    "\n",
    "        model_handler = model_utils.TorchModelHandler(use_cuda=use_cuda,\n",
    "                                                      checkpoint_path=config.get('ckp_path', 'data/checkpoints/'),\n",
    "                                                      result_path=config.get('res_path','data/gen-stance/'),\n",
    "                                                      **kwargs)\n",
    "\n",
    "    elif 'BasicAdv' in config['name']:\n",
    "        batch_args = {}\n",
    "        input_layer = bm.WordEmbedLayer(vecs=vecs, use_cuda=use_cuda)\n",
    "        setup_fn = data_utils.setup_helper_adv\n",
    "\n",
    "        loss_fn = lf.AdvBasicLoss(trans_dim=2*int(config['h']), trans_param=float(config['trans_w']),\n",
    "                                  num_no_adv=float(config['num_na']),\n",
    "                                  tot_epochs=int(config['epochs']),\n",
    "                                  rho_adv=('rho_adv' in config),\n",
    "                                  gamma=float(config.get('gamma', 10.0)),\n",
    "                                  semi_sup=('semi_sup' in config),\n",
    "                                  use_cuda=use_cuda)\n",
    "\n",
    "        enc_params = {'h': int(config['h']), 'embed_dim': input_layer.dim, 'drop_prob' : float(config['dropout'])}\n",
    "\n",
    "        model = bm.AdversarialBasic(enc_params=enc_params, enc_type=config['enc'],\n",
    "                                    stance_dim=int(config['sd']), topic_dim=int(config['td']),\n",
    "                                    num_labels=nl, num_topics=int(config['num_top']),\n",
    "                                    drop_prob=float(config['dropout']),\n",
    "                                    use_cuda=use_cuda)\n",
    "        \n",
    "        if 'optimizer' not in config:\n",
    "            #Adam optimizer\n",
    "            o_main = optim_fn(chain(model.enc.parameters(),\n",
    "                                model.recon_layer.parameters(),\n",
    "                                model.topic_recon_layer.parameters(),\n",
    "                                model.trans_layer.parameters(),\n",
    "                                model.stance_classifier.parameters()),\n",
    "                          lr=lr,\n",
    "                          weight_decay=float(config.get('l2_main', '0')))\n",
    "            o_adv = optim_fn(model.topic_classifier.parameters(),\n",
    "                             lr=lr,\n",
    "                             weight_decay=float(config.get('l2_adv', '0')))\n",
    "        elif config['optimizer'] == 'sgd':\n",
    "            #SGD optimizer\n",
    "            o_main = optim_fn(chain(model.enc.parameters(),\n",
    "                                    model.recon_layer.parameters(),\n",
    "                                    model.topic_recon_layer.parameters(),\n",
    "                                    model.trans_layer.parameters(),\n",
    "                                    model.stance_classifier.parameters()),\n",
    "                              lr=lr,\n",
    "                              weight_decay=float(config.get('l2_main', '0')),\n",
    "                              momentum=0.9,\n",
    "                              nesterov=True)\n",
    "            o_adv = optim_fn(model.topic_classifier.parameters(),\n",
    "                             lr=lr,\n",
    "                             weight_decay=float(config.get('l2_adv', '0')),\n",
    "                             momentum=0.9,\n",
    "                             nesterov=True)\n",
    "\n",
    "        kwargs = {'model': model, 'embed_model': input_layer, 'dataloader': dataloader,\n",
    "                  'batching_fn': data_utils.prepare_batch_adv,\n",
    "                  'batching_kwargs': batch_args, 'name': config['name'] + '-{}'.format(config['enc']) + args.name,\n",
    "                  'loss_function': loss_fn,\n",
    "                  'optimizer': o_main,\n",
    "                  'adv_optimizer': o_adv,\n",
    "                  'setup_fn': setup_fn,\n",
    "                  'tot_epochs': int(config['epochs']),\n",
    "                  'initial_lr': lr,\n",
    "                  'alpha': float(config.get('alpha', 10.0)),\n",
    "                  'beta': float(config.get('beta', 0.75)),\n",
    "                  'num_constant_lr': float(config['num_constant_lr']),\n",
    "                  'batch_size': int(config['b']),\n",
    "                  'blackout_start': int(config['blackout_start']),\n",
    "                  'blackout_stop': int(config['blackout_stop'])}\n",
    "\n",
    "        model_handler = model_utils.AdvTorchModelHandler(use_score=args.score_key, use_cuda=use_cuda,\n",
    "                                                         checkpoint_path=config.get('ckp_path', 'data/checkpoints/'),\n",
    "                                                         result_path=config.get('res_path', 'data/gen-stance/'),\n",
    "                                                         opt_for=config.get('opt', 'score_key'),\n",
    "                                                         **kwargs)\n",
    "\n",
    "    if args.mode == 'train':\n",
    "        # Train model\n",
    "        start_time = time.time()\n",
    "        train(model_handler, int(config['epochs']), dev_data=dev_dataloader,\n",
    "             num_warm=args.num_warm, phases=('phases' in config),is_adv=adv)\n",
    "        print(\"[{}] total runtime: {:.2f} minutes\".format(config['name'], (time.time() - start_time)/60.))\n",
    "\n",
    "    elif args.mode == 'eval':\n",
    "        # Evaluate saved model\n",
    "        model_handler.load(filename=args.saved_model_file_name)\n",
    "        eval_helper(model_handler,'DEV',data=dev_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9614b044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
